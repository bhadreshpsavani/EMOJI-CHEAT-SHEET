{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:huggingface]",
      "language": "python",
      "name": "conda-env-huggingface-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "T5-ClosedBook-TriviaQA-Github.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXQ9PxRAT0qk",
        "outputId": "da77cc72-aa04-4371-d909-b284874416fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!pip install -q pytorch_lightning\n",
        "!pip install -q transformers\n",
        "!pip install -q datasets\n",
        "!pip install -q --upgrade wandb"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7MB 9.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 26.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 14.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 53.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.8MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:48.937291Z",
          "start_time": "2020-09-30T02:16:48.925110Z"
        },
        "id": "p-FfyfeUMEHu",
        "outputId": "00651ea6-0e6a-429c-868e-4ba7c790f965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import argparse\n",
        "import glob\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import re\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from datasets import load_metric\n",
        "import string\n",
        "from pathlib import Path\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    Adafactor,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    T5Config,\n",
        "    get_linear_schedule_with_warmup\n",
        ")\n",
        "from torch.utils.data import RandomSampler"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuVV4mW5MEH-",
        "outputId": "687db47e-14d8-4dad-fe2f-5b6ddd6fd4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Login to WandB and get your API Key\n",
        "!wandb login fc638ba3015975823dace90bc636801c18b22216"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARKFZnANoy5Z"
      },
      "source": [
        "import wandb"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:48.946040Z",
          "start_time": "2020-09-30T02:16:48.939519Z"
        },
        "id": "7x4pcwSUMEIH"
      },
      "source": [
        "os.environ[\"WANDB_API_KEY\"] = 'fc638ba3015975823dace90bc636801c18b22216'\n",
        "wandb_logger = WandbLogger(project='triviaqa')\n",
        "# wandb.init(project=\"transformers_tutorials_summarization\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mBcG-_EMEIP"
      },
      "source": [
        "## Load Data using NLP Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.325849Z",
          "start_time": "2020-09-30T02:16:48.948065Z"
        },
        "id": "ulHXyG1eMEIR",
        "outputId": "7f56dbf2-ae97-485f-f6f3-62c8662f5ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from datasets import list_datasets\n",
        "datasets_list = list_datasets()\n",
        "print(', '.join(dataset for dataset in datasets_list))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aeslc, ag_news, ai2_arc, allocine, anli, arcd, art, billsum, biomrc, blended_skill_talk, blimp, blog_authorship_corpus, bookcorpus, boolq, break_data, c4, cfq, civil_comments, clue, cmrc2018, cnn_dailymail, coarse_discourse, com_qa, common_gen, commonsense_qa, compguesswhat, conll2000, conll2003, coqa, cornell_movie_dialog, cos_e, cosmos_qa, crd3, crime_and_punish, csv, daily_dialog, definite_pronoun_resolution, discofuse, docred, doqa, drop, eli5, emo, emotion, empathetic_dialogues, eraser_multi_rc, esnli, event2Mind, fever, flores, fquad, gap, germeval_14, gigaword, glue, guardian_authorship, hans, hansards, hellaswag, hotpot_qa, hyperpartisan_news_detection, imdb, iwslt2017, jeopardy, json, kilt_tasks, kilt_wikipedia, kor_nli, lc_quad, lhoestq/squad, librispeech_lm, lince, lm1b, math_dataset, math_qa, matinf, mlqa, mlsum, movie_rationales, ms_marco, multi_news, multi_nli, multi_nli_mismatch, mwsc, natural_questions, newsgroup, newsroom, openbookqa, openwebtext, opinosis, pandas, para_crawl, pg19, piaf, polyglot_ner, qa4mre, qa_zre, qangaroo, qanta, qasc, quail, quarel, quartz, quora, quoref, race, reclor, reddit, reddit_tifu, reuters21578, rotten_tomatoes, scan, scicite, scientific_papers, scifact, sciq, scitail, search_qa, sentiment140, snli, social_bias_frames, social_i_qa, sogou_news, squad, squad_es, squad_it, squad_v1_pt, squad_v2, squadshifts, sshleifer/pseudo_bart_xsum, style_change_detection, super_glue, ted_hrlr, ted_multi, text, tiny_shakespeare, trec, trivia_qa, tydiqa, ubuntu_dialogs_corpus, web_of_science, web_questions, wiki40b, wiki_dpr, wiki_qa, wiki_snippets, wiki_split, wikihow, wikipedia, wikisql, wikitext, winogrande, wiqa, wmt14, wmt15, wmt16, wmt17, wmt18, wmt19, wmt_t2t, wnut_17, x_stance, xcopa, xnli, xquad, xsum, xtreme, yelp_polarity\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTsf9kaFMEIg"
      },
      "source": [
        "### Select Trivia QA data set\n",
        "See more about it at - https://www.tensorflow.org/datasets/catalog/trivia_qa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.726602Z",
          "start_time": "2020-09-30T02:16:49.329660Z"
        },
        "id": "Y6sy0jBiMEIh",
        "outputId": "8b855450-41ae-4cbd-b493-4c333e89f7c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('trivia_qa', 'unfiltered.nocontext')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset trivia_qa (/root/.cache/huggingface/datasets/trivia_qa/unfiltered.nocontext/1.1.0/e734e28133f4d9a353af322aa52b9f266f6f27cbf2f072690a1694e577546b0d)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.730983Z",
          "start_time": "2020-09-30T02:16:49.728086Z"
        },
        "id": "XJU-QDpwMEIp",
        "outputId": "639747f2-b8fe-4ab8-db0f-6da856ea5453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(dataset.keys())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['train', 'validation', 'test'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.735861Z",
          "start_time": "2020-09-30T02:16:49.732451Z"
        },
        "id": "Jq934IJKMEIx",
        "outputId": "4ed21319-05af-4e5f-fc13-d9b1aa6a8036",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Size of train dataset: \", dataset['train'].shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of train dataset:  (87622, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.742998Z",
          "start_time": "2020-09-30T02:16:49.736881Z"
        },
        "id": "rjqfyapqMEI6",
        "outputId": "a2abf74f-fabe-4c04-fe1a-53e7202ebc95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Size of Validation dataset: \", dataset['validation'].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Validation dataset:  (11313, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1k6CONzMEJB"
      },
      "source": [
        "We can use the test data set for validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.748588Z",
          "start_time": "2020-09-30T02:16:49.744564Z"
        },
        "id": "CfAOTAOMMEJD",
        "outputId": "73e52040-a28d-4c20-b269-ca2a97241e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Size of ca test dataset: \", dataset['test'].shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of ca test dataset:  (10832, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-bLANNdMEJM"
      },
      "source": [
        "### Look at Examples in this data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.752631Z",
          "start_time": "2020-09-30T02:16:49.749858Z"
        },
        "id": "fBOosjpjMEJN",
        "outputId": "cf3d83ca-ee5a-4fb7-ffc0-2f1f10b78da2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(dataset['train'][0].keys())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['answer', 'entity_pages', 'question', 'question_id', 'question_source', 'search_results'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.757758Z",
          "start_time": "2020-09-30T02:16:49.753549Z"
        },
        "id": "W4eSwLPJMEJU",
        "outputId": "089ad0f5-82a8-444e-bbae-0340617a2deb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\" Example of Question: \", dataset['train'][6]['question'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Example of Question:  From which country did Angola achieve independence in 1975?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.763131Z",
          "start_time": "2020-09-30T02:16:49.758717Z"
        },
        "id": "ULC74-EuMEJc",
        "outputId": "211e0312-8488-4f9c-c871-f5e33c80cf55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\" Example of Answer: \", dataset['train'][6]['answer'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Example of Answer:  {'aliases': ['Portogało', 'Republic of Portugal', 'PORTUGAL', 'Portekiz', 'Portugallu', 'O Papagaio', 'ISO 3166-1:PT', 'Portunga', 'Phu-to-ga', 'Potigal', 'Portûnga', 'Portugul', 'An Phortaingéil', 'Portugāle', 'Portugale', 'Portingale', 'Potiti', 'Portugali', 'Portugall', 'Portekîz', 'Bo Dao Nha', 'Portuguese Republic', 'Portogallo', 'Portugaul', 'Portogalo', 'Portyngal', 'Yn Phortiugal', 'Portugalio', 'Portugál', 'Portugual', 'Portuga', 'Portgual', 'Portugalsko', 'Portugaleje', 'Phû-tô-gâ', 'Portugalujo', 'Portugalija', 'Pertual', 'Pòtigal', 'Portugal', 'Bồ Đào Nha', 'Portugalska', 'República Portuguesa', 'Portiwgal', 'Portugalėjė', 'Portúgal', 'Portegal', 'An Phortaingeil', 'Republica Portuguesa'], 'matched_wiki_entity_name': '', 'normalized_aliases': ['portûnga', 'portugalujo', 'portogalo', 'portiwgal', 'portugalio', 'portugalija', 'república portuguesa', 'portugāle', 'portugalėjė', 'portugaleje', 'portgual', 'potigal', 'portugallu', 'portogało', 'phortaingéil', 'portingale', 'portekîz', 'portugual', 'portugale', 'portugalska', 'yn phortiugal', 'portúgal', 'portugal', 'portugaul', 'phû tô gâ', 'portyngal', 'portunga', 'pertual', 'portugall', 'phortaingeil', 'portuguese republic', 'republica portuguesa', 'portekiz', 'iso 3166 1 pt', 'portugál', 'portuga', 'o papagaio', 'republic of portugal', 'bồ đào nha', 'potiti', 'phu to ga', 'portugalsko', 'pòtigal', 'portegal', 'portugul', 'portugali', 'portogallo', 'bo dao nha'], 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'portugal', 'type': 'WikipediaEntity', 'value': 'Portugal'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.767864Z",
          "start_time": "2020-09-30T02:16:49.764091Z"
        },
        "id": "qPq0kmIMMEJj",
        "outputId": "e14d4983-cc0b-4d37-b664-069cce8f2f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\" Example of Search Results: \", dataset['train'][6]['search_results'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Example of Search Results:  {'description': [], 'filename': [], 'rank': [], 'search_context': [], 'title': [], 'url': []}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "po_VhH_KMEJr"
      },
      "source": [
        "### Inputs for T5 Model\n",
        "Since this is a closed book question answering problem, we will take as input the question and fine tune the model to output the answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbixA0HrMEJs"
      },
      "source": [
        "### Estimate average length of Question and Answer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.774619Z",
          "start_time": "2020-09-30T02:16:49.768802Z"
        },
        "id": "0Qa2BHXtMEJu"
      },
      "source": [
        "tiny_dataset = dataset['train'].select(list(range(0, 100)))\n",
        "ques_len = []\n",
        "ans_len=[]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.792004Z",
          "start_time": "2020-09-30T02:16:49.775613Z"
        },
        "id": "_njkwsmDMEJ4"
      },
      "source": [
        "for i in range(len(tiny_dataset)):\n",
        "    example = tiny_dataset[i]\n",
        "    text_example = example['question']\n",
        "    text_example = text_example.replace('\\n','')\n",
        "    text_words = text_example.split()\n",
        "    ques_len.append(len(text_words))\n",
        "    summary_example = example['answer']['value']\n",
        "    summary_example = summary_example.replace('\\n','')\n",
        "    summary_words = summary_example.split()\n",
        "    ans_len.append(len(summary_words))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:49.918958Z",
          "start_time": "2020-09-30T02:16:49.793101Z"
        },
        "id": "niI3KMdGMEJ-",
        "outputId": "6abbc24c-185e-4177-eba9-336490a26bd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.hist(ques_len)\n",
        "plt.title('Question Length Distribution - First 100 examples')\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.019702Z",
          "start_time": "2020-09-30T02:16:49.919944Z"
        },
        "id": "6rTSrtl8MEKF",
        "outputId": "c7fb90ee-9f73-4278-bc0b-04031fd2d3c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.hist(ans_len)\n",
        "plt.title('Answer Length Distribution - First 100 examples')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.023017Z",
          "start_time": "2020-09-30T02:16:50.020646Z"
        },
        "id": "bnhQbGrhMEKN",
        "outputId": "85c148c3-5996-461a-b2b1-dfa403743567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Average Length of text: \", sum(ques_len)/len(ques_len))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Length of text:  9.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.029602Z",
          "start_time": "2020-09-30T02:16:50.023861Z"
        },
        "id": "kQy2bYOSMEKV",
        "outputId": "71293497-280c-4321-83c1-8ef2b99a6865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Average Length of Summary: \", sum(ans_len)/len(ans_len))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average Length of Summary:  1.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdZLP0bvMEKc"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.035786Z",
          "start_time": "2020-09-30T02:16:50.030553Z"
        },
        "id": "xThM0ptfMEKd"
      },
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.042722Z",
          "start_time": "2020-09-30T02:16:50.036697Z"
        },
        "id": "fvvx2v5XMEKk"
      },
      "source": [
        "def normalize_answer(s):\n",
        "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
        "\n",
        "    def remove_articles(text):\n",
        "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", text)\n",
        "\n",
        "    def white_space_fix(text):\n",
        "        return \" \".join(text.split())\n",
        "\n",
        "    def remove_punc(text):\n",
        "        exclude = set(string.punctuation)\n",
        "        return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "    def lower(text):\n",
        "        return text.lower()\n",
        "\n",
        "    return white_space_fix(remove_articles(remove_punc(lower(s))))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.049200Z",
          "start_time": "2020-09-30T02:16:50.043691Z"
        },
        "id": "fBp-TY8zMEKv"
      },
      "source": [
        "def exact_match_score(prediction, ground_truth):\n",
        "    return int(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "def approx_match_score(prediction, ground_truth):\n",
        "    answer = normalize_answer(prediction) \n",
        "    gt = normalize_answer(ground_truth)\n",
        "    match = 0\n",
        "    gt_words = gt.split(\" \")\n",
        "    for word in gt_words:\n",
        "        if word in answer:\n",
        "            match = 1\n",
        "            return match\n",
        "    return match"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.058980Z",
          "start_time": "2020-09-30T02:16:50.050120Z"
        },
        "id": "V0V8uAG3MEK1"
      },
      "source": [
        "def calculate_scores(predictions, ground_truths):\n",
        "    em_score = 0\n",
        "    subset_match_score = 0\n",
        "    \n",
        "    for i in range(len(predictions)):\n",
        "        ground_truth = ground_truths[i]\n",
        "        prediction = predictions[i]\n",
        "        em_score +=  exact_match_score(prediction, ground_truth)\n",
        "        subset_match_score += approx_match_score(prediction, ground_truth)\n",
        "    \n",
        "    em_score /= len(predictions)\n",
        "    subset_match_score /= len(predictions)\n",
        "    return em_score*100, subset_match_score*100\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.086493Z",
          "start_time": "2020-09-30T02:16:50.060866Z"
        },
        "id": "3L0bgbV3MEK6"
      },
      "source": [
        "class T5FineTuner(pl.LightningModule):\n",
        "    def __init__(self, hparams):\n",
        "        super(T5FineTuner, self).__init__()\n",
        "        self.hparams = hparams\n",
        "#         self.config = T5Config(hparams.model_name_or_path,dropout_rate=0.2)\n",
        "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
        "#         self.model.dropout_rate=0.2\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
        "        \n",
        "        if self.hparams.freeze_embeds:\n",
        "            self.freeze_embeds()\n",
        "        if self.hparams.freeze_encoder:\n",
        "            self.freeze_params(self.model.get_encoder())\n",
        "            assert_all_frozen(self.model.get_encoder())\n",
        "        \n",
        "        self.step_count = 0\n",
        "        self.output_dir = Path(self.hparams.output_dir)\n",
        "            \n",
        "        n_observations_per_split = {\n",
        "            \"train\": self.hparams.n_train,\n",
        "            \"validation\": self.hparams.n_val,\n",
        "            \"test\": self.hparams.n_test,\n",
        "        }\n",
        "        self.n_obs = {k: v if v >= 0 else None for k, v in n_observations_per_split.items()}\n",
        "        self.em_score_list = []\n",
        "        self.subset_score_list =[]\n",
        "    \n",
        "    def freeze_params(self, model):\n",
        "        for par in model.parameters():\n",
        "            par.requires_grad = False\n",
        "            \n",
        "            \n",
        "    def freeze_embeds(self):\n",
        "        \"\"\"Freeze token embeddings and positional embeddings for bart, just token embeddings for t5.\"\"\"\n",
        "        try:\n",
        "            self.freeze_params(self.model.model.shared)\n",
        "            for d in [self.model.model.encoder, self.model.model.decoder]:\n",
        "                freeze_params(d.embed_positions)\n",
        "                freeze_params(d.embed_tokens)\n",
        "        except AttributeError:\n",
        "            self.freeze_params(self.model.shared)\n",
        "            for d in [self.model.encoder, self.model.decoder]:\n",
        "                self.freeze_params(d.embed_tokens)\n",
        "    \n",
        "    def lmap(self, f, x):\n",
        "        \"\"\"list(map(f, x))\"\"\"\n",
        "        return list(map(f, x))\n",
        "    \n",
        "\n",
        "    def is_logger(self):\n",
        "        return self.trainer.proc_rank <= 0\n",
        "    \n",
        "        \n",
        "    def forward(\n",
        "      self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, lm_labels=None\n",
        "  ):\n",
        "        return self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            lm_labels=lm_labels,\n",
        "    )\n",
        "\n",
        "    def _step(self, batch):\n",
        "        lm_labels = batch[\"target_ids\"]\n",
        "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            lm_labels=lm_labels,\n",
        "            decoder_attention_mask=batch['target_mask']\n",
        "        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        return loss\n",
        "    \n",
        "    \n",
        "    def ids_to_clean_text(self, generated_ids):\n",
        "        gen_text = self.tokenizer.batch_decode(\n",
        "            generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
        "        )\n",
        "        return self.lmap(str.strip, gen_text)\n",
        "    \n",
        "    \n",
        "    def _generative_step(self, batch) :\n",
        "        \n",
        "        t0 = time.time()\n",
        "        \n",
        "        generated_ids = self.model.generate(\n",
        "            batch[\"source_ids\"],\n",
        "            attention_mask=batch[\"source_mask\"],\n",
        "            use_cache=True,\n",
        "            decoder_attention_mask=batch['target_mask'],\n",
        "            max_length=10,\n",
        "            num_beams=2,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        preds = self.ids_to_clean_text(generated_ids)\n",
        "        targets = self.ids_to_clean_text(batch[\"target_ids\"])\n",
        "            \n",
        "        gen_time = (time.time() - t0) / batch[\"source_ids\"].shape[0]  \n",
        "    \n",
        "        loss = self._step(batch)\n",
        "        base_metrics = {'val_loss': loss}\n",
        "        summ_len = np.mean(self.lmap(len, generated_ids))\n",
        "        base_metrics.update(gen_time=gen_time, gen_len=summ_len, preds=preds, target=targets)\n",
        "        em_score, subset_match_score = calculate_scores(preds, targets)\n",
        "        \n",
        "        self.em_score_list.append(em_score)\n",
        "        self.subset_score_list.append(subset_match_score)\n",
        "        \n",
        "        em_score = torch.tensor(em_score,dtype=torch.float32)\n",
        "        subset_match_score = torch.tensor(subset_match_score,dtype=torch.float32)\n",
        "        \n",
        "        base_metrics.update(em_score=em_score, subset_match_score=subset_match_score)\n",
        "        \n",
        "#         rouge_results = self.rouge_metric.compute() \n",
        "#         rouge_dict = self.parse_score(rouge_results)\n",
        "\n",
        "        \n",
        "        return base_metrics\n",
        "    \n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self._step(batch)\n",
        "\n",
        "        tensorboard_logs = {\"train_loss\": loss}\n",
        "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "  \n",
        "    def training_epoch_end(self, outputs):\n",
        "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
        "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
        "        return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self._generative_step(batch)\n",
        "    \n",
        "  \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        \n",
        "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
        "        \n",
        "        if len(self.em_score_list) <= 2:\n",
        "            average_em_score = sum(self.em_score_list) / len(self.em_score_list) \n",
        "            average_subset_match_score = sum(self.subset_score_list)/len(self.subset_score_list)\n",
        "            \n",
        "        else:\n",
        "            latest_em_score = self.em_score_list[:-2]\n",
        "            latest_subset_score = self.subset_score_list[:-2]\n",
        "            average_em_score = sum(latest_em_score) / len(latest_em_score) \n",
        "            average_subset_match_score = sum(latest_subset_score)/len(latest_subset_score)\n",
        "            \n",
        "        \n",
        "        \n",
        "        average_em_score = torch.tensor(average_em_score,dtype=torch.float32)\n",
        "        average_subset_match_score = torch.tensor(average_subset_match_score,dtype=torch.float32)\n",
        "        tensorboard_logs.update(em_score=average_em_score, subset_match_score=average_subset_match_score)\n",
        "        \n",
        "        ## Clear out the lists for next epoch\n",
        "        self.target_gen= []\n",
        "        self.prediction_gen=[]\n",
        "        return {\"avg_val_loss\": avg_loss, \n",
        "                \"em_score\" : average_em_score,\n",
        "                \"subset_match_score\" : average_subset_match_score,\n",
        "                \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "        model = self.model\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": self.hparams.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "        ]\n",
        "        \n",
        "#         optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
        "        optimizer = Adafactor(optimizer_grouped_parameters, lr=self.hparams.learning_rate, scale_parameter=False,\n",
        "                             relative_step=False)\n",
        "        self.opt = optimizer\n",
        "        return [optimizer]\n",
        "  \n",
        "    def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None, using_native_amp=False):\n",
        "        if self.trainer.use_tpu:\n",
        "            xm.optimizer_step(optimizer)\n",
        "        else:\n",
        "            optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        self.lr_scheduler.step()\n",
        "  \n",
        "    def get_tqdm_dict(self):\n",
        "        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
        "\n",
        "        return tqdm_dict\n",
        "    \n",
        "\n",
        "    def train_dataloader(self):   \n",
        "        n_samples = self.n_obs['train']\n",
        "        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", num_samples=n_samples, args=self.hparams)\n",
        "        sampler=RandomSampler(train_dataset)\n",
        "        dataloader = DataLoader(train_dataset, sampler=sampler,  batch_size=self.hparams.train_batch_size, drop_last=True, num_workers=4)\n",
        "        t_total = (\n",
        "            (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
        "            // self.hparams.gradient_accumulation_steps\n",
        "            * float(self.hparams.num_train_epochs)\n",
        "        )\n",
        "        t_total = 100000\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
        "        )\n",
        "        self.lr_scheduler = scheduler\n",
        "        return dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        n_samples = self.n_obs['validation']\n",
        "        \n",
        "        validation_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"validation\", num_samples=n_samples, args=self.hparams)\n",
        "        sampler=RandomSampler(validation_dataset)\n",
        "        return DataLoader(validation_dataset, batch_size=self.hparams.eval_batch_size, sampler =sampler, num_workers=4)\n",
        "    \n",
        "    \n",
        "    def test_dataloader(self):\n",
        "        n_samples = self.n_obs['test']\n",
        "        test_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"test\", num_samples=n_samples, args=self.hparams)\n",
        "        \n",
        "        return DataLoader(test_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
        "    \n",
        "    \n",
        "    def on_save_checkpoint(self, checkpoint):\n",
        "        save_path = self.output_dir.joinpath(\"best_tfmr\")\n",
        "        self.model.config.save_step = self.step_count\n",
        "        self.model.save_pretrained(save_path)\n",
        "        self.tokenizer.save_pretrained(save_path)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.093280Z",
          "start_time": "2020-09-30T02:16:50.087601Z"
        },
        "id": "BYCHT4F8MELC"
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        logger.info(\"***** Validation results *****\")\n",
        "        if pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "            # Log results\n",
        "            for key in sorted(metrics):\n",
        "                if key not in [\"log\", \"progress_bar\"]:\n",
        "                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "    def on_test_end(self, trainer, pl_module):\n",
        "        logger.info(\"***** Test results *****\")\n",
        "\n",
        "        if pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "\n",
        "            # Log and save results to file\n",
        "            output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
        "            with open(output_test_results_file, \"w\") as writer:\n",
        "                for key in sorted(metrics):\n",
        "                    if key not in [\"log\", \"progress_bar\"]:\n",
        "                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                        writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMI1OruhMELI"
      },
      "source": [
        "## Define a DataSet class for the loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.101660Z",
          "start_time": "2020-09-30T02:16:50.094254Z"
        },
        "id": "bx-AQckRMELJ"
      },
      "source": [
        "class Trivia_QA_Closedbook(Dataset):\n",
        "    def __init__(self, tokenizer, type_path, num_samples, input_length, output_length, print_text=False):         \n",
        "        self.dataset =  load_dataset('trivia_qa', 'unfiltered.nocontext', split=type_path)\n",
        "        if num_samples:\n",
        "            rand_indices = np.random.choice(self.dataset.shape[0], num_samples, replace=False)\n",
        "            self.dataset = self.dataset.select(list(rand_indices))\n",
        "        self.input_length = input_length\n",
        "        self.tokenizer = tokenizer\n",
        "        self.output_length = output_length\n",
        "        self.print_text = print_text\n",
        "  \n",
        "    def __len__(self):\n",
        "        return self.dataset.shape[0]\n",
        "    \n",
        "    def clean_text(self, text):\n",
        "        text = text.replace('Example of text:', '')\n",
        "        text = text.replace('Example of Summary:', '')\n",
        "        text = text.replace('\\n','')\n",
        "        text = text.replace('``', '')\n",
        "        text = text.replace('\"', '')\n",
        "        \n",
        "        return text\n",
        "    \n",
        "    \n",
        "    def convert_to_features(self, example_batch):\n",
        "        # Tokenize contexts and questions (as pairs of inputs)\n",
        "        \n",
        "        if self.print_text:\n",
        "            print(\"Input Text: \", self.clean_text(example_batch['question']))\n",
        "#         input_ = self.clean_text(example_batch['text']) + \" </s>\"\n",
        "#         target_ = self.clean_text(example_batch['headline']) + \" </s>\"\n",
        "        \n",
        "        input_ = self.clean_text(example_batch['question'])  \n",
        "        target_ = self.clean_text(example_batch['answer']['value'])  \n",
        "        \n",
        "        source = self.tokenizer.batch_encode_plus([input_], max_length=self.input_length, \n",
        "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "        \n",
        "        targets = self.tokenizer.batch_encode_plus([target_], max_length=self.output_length, \n",
        "                                                     padding='max_length', truncation=True, return_tensors=\"pt\")\n",
        "    \n",
        "       \n",
        "        return source, targets\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        source, targets = self.convert_to_features(self.dataset[index])\n",
        "        \n",
        "        source_ids = source[\"input_ids\"].squeeze()\n",
        "        target_ids = targets[\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask    = source[\"attention_mask\"].squeeze()\n",
        "        target_mask = targets[\"attention_mask\"].squeeze()\n",
        "\n",
        "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
        "        \n",
        "  "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmFlbOypMELQ"
      },
      "source": [
        "### Test the dataset function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.708768Z",
          "start_time": "2020-09-30T02:16:50.102627Z"
        },
        "id": "oX332hZCMELR",
        "outputId": "262ba1e9-c77f-45b9-935c-b25b47c851b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "dataset = Trivia_QA_Closedbook(tokenizer, 'validation', None, 25, 10, True)\n",
        "len(dataset)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reusing dataset trivia_qa (/root/.cache/huggingface/datasets/trivia_qa/unfiltered.nocontext/1.1.0/e734e28133f4d9a353af322aa52b9f266f6f27cbf2f072690a1694e577546b0d)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11313"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.717827Z",
          "start_time": "2020-09-30T02:16:50.710397Z"
        },
        "id": "oleR_DH1MELX",
        "outputId": "3d0b1da3-2f17-4c71-abf7-fc01b66ae58b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "data = dataset[50]\n",
        "print()\n",
        "print(\"Shape of Tokenized Text: \", data['source_ids'].shape)\n",
        "print()\n",
        "print(\"Sanity check - Decode Text: \", tokenizer.decode(data['source_ids']))\n",
        "print(\"====================================\")\n",
        "print(\"Sanity check - Decode Summary: \", tokenizer.decode(data['target_ids']))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Text:  Kagoshima international airport is in which country?\n",
            "\n",
            "Shape of Tokenized Text:  torch.Size([25])\n",
            "\n",
            "Sanity check - Decode Text:  Kagoshima international airport is in which country?\n",
            "====================================\n",
            "Sanity check - Decode Summary:  Japan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpo8gi7ZMELc"
      },
      "source": [
        "## Define Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.723462Z",
          "start_time": "2020-09-30T02:16:50.719135Z"
        },
        "id": "cN6rr66KMELd"
      },
      "source": [
        "args_dict = dict(\n",
        "    output_dir=\"\", # path to save the checkpoints\n",
        "    model_name_or_path='t5-base',\n",
        "    tokenizer_name_or_path='t5-base',\n",
        "    max_input_length=25,\n",
        "    max_output_length=10,\n",
        "    freeze_encoder=False,\n",
        "    freeze_embeds=False,\n",
        "    learning_rate=1e-5,\n",
        "    weight_decay=0.0,\n",
        "    adam_epsilon=1e-8,\n",
        "    warmup_steps=0,\n",
        "    train_batch_size=4,\n",
        "    eval_batch_size=4,\n",
        "    num_train_epochs=2,\n",
        "    gradient_accumulation_steps=10,\n",
        "    n_gpu=1,\n",
        "    resume_from_checkpoint=None, \n",
        "    val_check_interval = 0.5, \n",
        "    n_val=5000,\n",
        "    n_train=-1,\n",
        "    n_test=-1,\n",
        "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
        "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
        "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
        "    seed=101,\n",
        ")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-22T20:38:51.721401Z",
          "start_time": "2020-09-22T20:38:51.492379Z"
        },
        "id": "iGg8X_-SMELl"
      },
      "source": [
        "!mkdir -p t5_trivia_qa_closedbook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.730274Z",
          "start_time": "2020-09-30T02:16:50.724667Z"
        },
        "id": "4TH_T2EVMELm",
        "outputId": "5ec8093a-489d-462c-fe0c-2375e9135f78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "args_dict.update({'output_dir': 't5_trivia_qa_closedbook', 'num_train_epochs':150,\n",
        "                 'train_batch_size': 48, 'eval_batch_size': 48, 'learning_rate': 1e-3,\n",
        "                 'resume_from_checkpoint': 't5_trivia_qa_closedbook/checkpointepoch=53.ckpt'})\n",
        "args = argparse.Namespace(**args_dict)\n",
        "print(args_dict)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'output_dir': 't5_trivia_qa_closedbook', 'model_name_or_path': 't5-base', 'tokenizer_name_or_path': 't5-base', 'max_input_length': 25, 'max_output_length': 10, 'freeze_encoder': False, 'freeze_embeds': False, 'learning_rate': 0.001, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 48, 'eval_batch_size': 48, 'num_train_epochs': 150, 'gradient_accumulation_steps': 10, 'n_gpu': 1, 'resume_from_checkpoint': 't5_trivia_qa_closedbook/checkpointepoch=53.ckpt', 'val_check_interval': 0.5, 'n_val': 5000, 'n_train': -1, 'n_test': -1, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 101}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.736501Z",
          "start_time": "2020-09-30T02:16:50.731289Z"
        },
        "id": "W224ntbDMELs"
      },
      "source": [
        "## Define Checkpoint function\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "    filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"em_score\", mode=\"max\", save_top_k=1\n",
        ")\n",
        "\n",
        "## If resuming from checkpoint, add an arg resume_from_checkpoint\n",
        "train_params = dict(\n",
        "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "    gpus=args.n_gpu,\n",
        "    max_epochs=args.num_train_epochs,\n",
        "    precision= 16 if args.fp_16 else 32,\n",
        "    amp_level=args.opt_level,\n",
        "    resume_from_checkpoint=args.resume_from_checkpoint,\n",
        "    gradient_clip_val=args.max_grad_norm,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    val_check_interval=args.val_check_interval,\n",
        "    logger=wandb_logger,\n",
        "    callbacks=[LoggingCallback()],\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:50.742698Z",
          "start_time": "2020-09-30T02:16:50.737468Z"
        },
        "id": "i7B8K8coMELx"
      },
      "source": [
        "def get_dataset(tokenizer, type_path, num_samples, args):\n",
        "      return Trivia_QA_Closedbook(tokenizer=tokenizer, type_path=type_path, num_samples=num_samples,  input_length=args.max_input_length, \n",
        "                        output_length=args.max_output_length)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwB3Ti2AMEL2"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:55.885876Z",
          "start_time": "2020-09-30T02:16:50.743664Z"
        },
        "id": "B5NNKFdcMEL3"
      },
      "source": [
        "model = T5FineTuner(args)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T02:16:55.890446Z",
          "start_time": "2020-09-30T02:16:55.886816Z"
        },
        "id": "_bqZnea9MEL8",
        "outputId": "23f014dd-55bd-4fe8-b8f3-bcb0baaae9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "trainer = pl.Trainer(**train_params)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T13:17:29.597096Z",
          "start_time": "2020-09-30T02:16:55.891613Z"
        },
        "id": "_rOHshSMMEMF",
        "outputId": "aa6e1583-72ef-430f-9566-56eed5fe4a46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "trainer.fit(model)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  | Name  | Type                       | Params\n",
            "-----------------------------------------------------\n",
            "0 | model | T5ForConditionalGeneration | 222 M \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-45d4afebefac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# set up training routine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36msetup_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# restore training and model before hpc is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# on pretrain routine end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py\u001b[0m in \u001b[0;36mrestore_weights\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdid_restore_hpc_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# wait for all to catch up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, checkpoint_path, on_gpu)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# else:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# load on CPU first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;31m# load model state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/cloud_io.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path_or_url, map_location)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_filesystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmap_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, block_size, cache_options, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m                 \u001b[0mautocommit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m                 \u001b[0mcache_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m             )\n\u001b[1;32m    905\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_mkdir\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLocalFileOpener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtouch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, autocommit, fs, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautocommit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocommit\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;31m# TODO: check if path is writable?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/t5_trivia_qa_closedbook/checkpointepoch=53.ckpt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WICHjZEKMEMM"
      },
      "source": [
        "## Check Model Predictions on Trivia Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T13:17:33.772166Z",
          "start_time": "2020-09-30T13:17:33.768555Z"
        },
        "id": "QN_0yAVmMEMN"
      },
      "source": [
        "import textwrap\n",
        "from tqdm.auto import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T13:17:36.922720Z",
          "start_time": "2020-09-30T13:17:36.241365Z"
        },
        "id": "HdHtpLYeMEMU"
      },
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "dataset = Trivia_QA_Closedbook(tokenizer, 'validation', None, 25, 10, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T13:17:39.528475Z",
          "start_time": "2020-09-30T13:17:39.499243Z"
        },
        "id": "Na-derJ7MEMb"
      },
      "source": [
        "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "it = iter(loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T13:17:42.627195Z",
          "start_time": "2020-09-30T13:17:42.555221Z"
        },
        "id": "qC3mj22CMEMg",
        "outputId": "9ff372c7-bb85-467d-c19f-82197fb00ab0"
      },
      "source": [
        "batch = next(it)\n",
        "batch[\"source_ids\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 25])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T13:17:45.215943Z",
          "start_time": "2020-09-30T13:17:44.768220Z"
        },
        "id": "V_EfmkzAMEMu"
      },
      "source": [
        "model.to('cuda')\n",
        "outs = model.model.generate(\n",
        "            batch[\"source_ids\"].cuda(),\n",
        "            attention_mask=batch[\"source_mask\"].cuda(),\n",
        "            use_cache=True,\n",
        "            decoder_attention_mask=batch['target_mask'].cuda(),\n",
        "            max_length=10,\n",
        "            num_beams=2,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "dec = [tokenizer.decode(ids) for ids in outs]\n",
        "\n",
        "texts = [tokenizer.decode(ids) for ids in batch['source_ids']]\n",
        "targets = [tokenizer.decode(ids) for ids in batch['target_ids']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T13:17:48.270784Z",
          "start_time": "2020-09-30T13:17:48.255338Z"
        },
        "scrolled": false,
        "id": "Hi59IemJMEM0",
        "outputId": "bb6f6d02-7c1f-4157-9537-4be47abc8cf8"
      },
      "source": [
        "for i in range(10):\n",
        "    lines = textwrap.wrap(\"Trivia Question:\\n%s\\n\" % texts[i], width=100)\n",
        "    print(\"\\n\".join(lines))\n",
        "    print(\"\\nActual Answer: %s\" % targets[i])\n",
        "    print(\"\\nPredicted Answer from T5: %s\" % dec[i])\n",
        "    print(\"=====================================================================\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trivia Question: US veterinary pathologist Daniel Salmon (1850-1914) oversaw the discovery of what,\n",
            "named eponym\n",
            "\n",
            "Actual Answer: Salmonella\n",
            "\n",
            "Predicted Answer from T5: Undiscovered ancestor\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: What are the traditional words used to vote in the British House of Lords?\n",
            "\n",
            "Actual Answer: Content / Non content\n",
            "\n",
            "Predicted Answer from T5: Turn of the clock\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Which American singer-songwriter wrote 'Sweet Baby James', the title track of his\n",
            "second album in\n",
            "\n",
            "Actual Answer: James Taylor\n",
            "\n",
            "Predicted Answer from T5: JEFFREY ARCHER\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Released in 1962, which was the first of the 'Carry On....' films to be released in\n",
            "\n",
            "Actual Answer: 'CARRY ON CRUIS\n",
            "\n",
            "Predicted Answer from T5: 'CARRY ON SERGE\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: In January 1968 who was chosen as leader of the Communist Party in Czechoslovakia?\n",
            "\n",
            "Actual Answer: Alexander Dubcek\n",
            "\n",
            "Predicted Answer from T5: Radovan Karadzic\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: What was placed in Earth’s orbit by Discovery in 1990?\n",
            "\n",
            "Actual Answer: Hubble Telescope\n",
            "\n",
            "Predicted Answer from T5: Mars\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Which English peer and courtier has been the most popular candidate proposed for\n",
            "the authorship of Shakespeare’s works?\n",
            "\n",
            "Actual Answer: Edward de Vere 17th Earl of Oxford\n",
            "\n",
            "Predicted Answer from T5: Sir Arthur Conan Doyle\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: 'An Island Parish' is a documentary series on BBC2, in which islands were the first\n",
            "four series set\n",
            "\n",
            "Actual Answer: Scilly Isles\n",
            "\n",
            "Predicted Answer from T5: Paragon\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Which actress and singer's biography was entitled 'The Other Side Of The Rainbow'?\n",
            "\n",
            "Actual Answer: JUDY GARLAND\n",
            "\n",
            "Predicted Answer from T5: SANDRA BULLOCK\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: ‘Troilus and ‘who’ is the title of a play by William Shakespeare?\n",
            "\n",
            "Actual Answer: Cressida\n",
            "\n",
            "Predicted Answer from T5: Shrew\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Which football team plays its home games at Portman Road?\n",
            "\n",
            "Actual Answer: Ipswich Town\n",
            "\n",
            "Predicted Answer from T5: Port Jackson\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Which car was nicknamed 'The Tiddler' and the 'Baby Austin'?\n",
            "\n",
            "Actual Answer: AUSTIN SEVEN\n",
            "\n",
            "Predicted Answer from T5: Classic\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: The works of which dramatic writer feature at least 64 bird species including all\n",
            "seven British crows?\n",
            "\n",
            "Actual Answer: William Shakepeare\n",
            "\n",
            "Predicted Answer from T5: Edgar Allan Poe\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: By what name was the African state of Namibia previously known?\n",
            "\n",
            "Actual Answer: SOUTH-WEST AFRICA\n",
            "\n",
            "Predicted Answer from T5: ANGOLA\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: In which New York borough would you find Hell’s Kitchen?\n",
            "\n",
            "Actual Answer: Manhattan\n",
            "\n",
            "Predicted Answer from T5: Manhattan\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: In which country is the Mekong Delta?\n",
            "\n",
            "Actual Answer: Vietnam\n",
            "\n",
            "Predicted Answer from T5: THAILAND\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: What notorious outlaw was shot in the back by the coward Robert Ford?\n",
            "\n",
            "Actual Answer: Jesse James\n",
            "\n",
            "Predicted Answer from T5: Al Capone\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Which daily newspaper was founded in 1903 by Alfred Harmsworth as a 'newspaper for\n",
            "women,\n",
            "\n",
            "Actual Answer: Daily Mirror\n",
            "\n",
            "Predicted Answer from T5: Daily Mirror\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: At which film festival could you be awarded the 'Palm d'Or'?\n",
            "\n",
            "Actual Answer: Cannes\n",
            "\n",
            "Predicted Answer from T5: Berlin\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: A year ago today saw an explosion on what Gulf of Mexico oil drilling platform,\n",
            "operated by BP?\n",
            "\n",
            "Actual Answer: Deepwater Horizon\n",
            "\n",
            "Predicted Answer from T5: Deepwater Horizon\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Gibraltar is linked by ferry to which North African city?\n",
            "\n",
            "Actual Answer: Tangier\n",
            "\n",
            "Predicted Answer from T5: Tunis\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Odysseus was King of which Greek state?\n",
            "\n",
            "Actual Answer: Ithaca\n",
            "\n",
            "Predicted Answer from T5: PYTHONY\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: A warm sunny period in Autumn (Fall) in the northern hemisphere is called an?\n",
            "\n",
            "Actual Answer: Indian Summer\n",
            "\n",
            "Predicted Answer from T5: Spring\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Typically, a male moose sheds its antlers how frequently?\n",
            "\n",
            "Actual Answer: Every year\n",
            "\n",
            "Predicted Answer from T5: 1.5 to 2 metres\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: The Victorian producer Richard d'Oyly Carte is most associated with the staging of\n",
            "whose works?\n",
            "\n",
            "Actual Answer: GILBERT AND SULLIV\n",
            "\n",
            "Predicted Answer from T5: Cecil Rhodes\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: The United Nations Organisation UNHRC looks at what specific issue?\n",
            "\n",
            "Actual Answer: HUMAN RIGHTS\n",
            "\n",
            "Predicted Answer from T5: Global climate\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: In which US city do the basketball team known as the 'Trail Blazers' play their\n",
            "home games?\n",
            "\n",
            "Actual Answer: PORTLAND, Oregon\n",
            "\n",
            "Predicted Answer from T5: SHREWSBURY\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: BAFTA winning film The Theory of Everything is adapted from which book?\n",
            "\n",
            "Actual Answer: Travelling to Infinity: My Life with\n",
            "\n",
            "Predicted Answer from T5: Atlas Shrugged\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: The Suez Canal connects the Mediterranean Sea to which other Sea?\n",
            "\n",
            "Actual Answer: Red sea\n",
            "\n",
            "Predicted Answer from T5: Sea of Marmara\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: What name is given to a woman divorced, separated, or living away from her spouse?\n",
            "\n",
            "Actual Answer: Grass widow\n",
            "\n",
            "Predicted Answer from T5: divorce\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: In which conflict was the 'Battle Of The Saintes', in 1782?\n",
            "\n",
            "Actual Answer: AMERICAN WAR OF IND\n",
            "\n",
            "Predicted Answer from T5: THE BAY OF PIGS\n",
            "=====================================================================\n",
            "\n",
            "Trivia Question: Ecuador has a border with Peru and which other country?\n",
            "\n",
            "Actual Answer: Colombia\n",
            "\n",
            "Predicted Answer from T5: ARGENTINA\n",
            "=====================================================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEGcOqqpMEM9"
      },
      "source": [
        "## Testing using AutoModel loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-06T12:09:58.847269Z",
          "start_time": "2020-09-06T12:09:58.842207Z"
        },
        "id": "4mXDkDDgMEM-"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-06T12:10:01.759433Z",
          "start_time": "2020-09-06T12:09:58.850750Z"
        },
        "id": "ISCmf7JTMEND"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"deep-learning-analytics/triviaqa-t5-base\")\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"deep-learning-analytics/triviaqa-t5-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-30T16:07:47.283895Z",
          "start_time": "2020-09-30T16:07:47.184319Z"
        },
        "id": "t8HCJqWxMENK",
        "outputId": "1a51460a-3c6f-49bb-804e-004edaeb78fa"
      },
      "source": [
        "text = \"Mount Everest is found in which mountain range?\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "preprocess_text = text.strip().replace(\"\\n\",\"\")\n",
        "tokenized_text = tokenizer.encode(preprocess_text, return_tensors=\"pt\").to(device)\n",
        "model = model.to(device)\n",
        "\n",
        "outs = model.model.generate(\n",
        "            tokenized_text,\n",
        "            max_length=10,\n",
        "            num_beams=2,\n",
        "            early_stopping=True\n",
        "           )\n",
        "\n",
        "dec = [tokenizer.decode(ids) for ids in outs]\n",
        "print(\"Predicted Answer: \", dec)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Answer:  ['Himalayas']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgmtEPmyMENQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}